{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# current_path = os.getcwd()\n",
    "# repo_dir = Path(current_path).parents[0]\n",
    "# data_dir = repo_dir / 'data'\n",
    "# if repo_dir not in sys.path:\n",
    "#     sys.path.append(repo_dir)\n",
    "    \n",
    "repo_dir = os.path.abspath(os.path.join('..'))\n",
    "if repo_dir not in sys.path:\n",
    "    sys.path.append(repo_dir)\n",
    "\n",
    "import argparse\n",
    "from functools import partial\n",
    "import json\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "from toolbox.data import load_set\n",
    "from toolbox.models import get_model\n",
    "from toolbox.experiment import Experiment\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.engine.topology import Layer\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import InputLayer\n",
    "from keras import backend as K\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sub_images(image, size, stride):\n",
    "    for i in range(0, image.size[0] - size + 1, stride):\n",
    "        for j in range(0, image.size[1] - size + 1, stride):\n",
    "            yield image.crop([i, j, i + size, j + size])\n",
    "            \n",
    "def array_to_img(x, mode='YCbCr'):\n",
    "    if mode == 'gray':\n",
    "        return Image.fromarray(x.astype('uint8')).convert('RGB')\n",
    "    else:\n",
    "        return Image.fromarray(x.astype('uint8'), mode=mode).convert('RGB')\n",
    "\n",
    "\n",
    "\n",
    "def bicubic_rescale(image, scale):\n",
    "    if isinstance(scale, (float, int)):\n",
    "        size = (np.array(image.size) * scale).astype(int)\n",
    "    return image.resize(size, resample=Image.BICUBIC)\n",
    "\n",
    "def img_downscale(image, scale = 4):\n",
    "    if len(image.shape)==3: # color image\n",
    "        down_size = np.int64(np.array(image.shape[0:2])/scale)\n",
    "        img_downscale = np.zeros(np.append(down_size, image.shape[2]))\n",
    "        for x in range(down_size[0]): #row\n",
    "            for y in range(down_size[1]): # column\n",
    "                X = x * scale\n",
    "                Y = y * scale\n",
    "                img_downscale[x, y] = image[X,Y]\n",
    "        return img_downscale\n",
    "    else: # gray_scale\n",
    "        down_size = np.uint8(np.array(image.shape)/scale)\n",
    "        img_downscale = np.zeros(down_size)\n",
    "        for x in range(down_size[0]): #row\n",
    "            for y in range(down_size[1]): # column\n",
    "                X = x * scale\n",
    "                Y = y * scale\n",
    "                img_downscale[x, y] = image[X,Y]\n",
    "        return img_downscale\n",
    "\n",
    "\n",
    "def modcrop(image, scale):\n",
    "    size = np.array(image.size)\n",
    "    size -= size % scale\n",
    "    return image.crop([0, 0, *size])\n",
    "\n",
    "def load_set(name, lr_sub_size=11, lr_sub_stride=5, scale=3):\n",
    "    hr_sub_size = lr_sub_size * scale\n",
    "    hr_sub_stride = lr_sub_stride * scale\n",
    "    lr_sub_arrays = []\n",
    "    hr_sub_arrays = []\n",
    "    for path in (data_dir / name).glob('*'):        \n",
    "        image = load_img(path)\n",
    "        image = image.convert('YCbCr')\n",
    "        hr_image = modcrop(image, scale)\n",
    "        lr_image = bicubic_rescale(hr_image, 1 / scale)\n",
    "        lr_sub_arrays += [img_to_array(img) for img in generate_sub_images(lr_image, size=lr_sub_size, stride=lr_sub_stride)]\n",
    "        hr_sub_arrays += [img_to_array(img) for img in generate_sub_images(hr_image, size=hr_sub_size, stride=hr_sub_stride)]\n",
    "    x = np.stack(lr_sub_arrays)\n",
    "    y = np.stack(hr_sub_arrays)\n",
    "    return x, y\n",
    "\n",
    "def ensure_dimension(array, dim):\n",
    "    while len(array.shape) < dim:\n",
    "        array = array[np.newaxis, ...]\n",
    "    return array\n",
    "\n",
    "def ensure_channel(array, c):\n",
    "    return array[..., c:c+1]\n",
    "\n",
    "def pre_process(array):\n",
    "    array = ensure_dimension(array, 4)\n",
    "    array = ensure_channel(array, 0)\n",
    "    return array\n",
    "\n",
    "def post_process(array, auxiliary_array):\n",
    "    array = np.concatenate([array, auxiliary_array[..., 1:]], axis=-1)\n",
    "    array = np.clip(array, 0, 255)\n",
    "    return array\n",
    "\n",
    "def inverse_post_process(array):\n",
    "    array = ensure_dimension(array, 4)\n",
    "    array = ensure_channel(array, 0)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ImageRescale(Layer):\n",
    "    def __init__(self, scale, method=tf.image.ResizeMethod.BICUBIC,\n",
    "                 trainable=False, **kwargs):\n",
    "        self.scale = scale\n",
    "        self.method = method\n",
    "        super().__init__(trainable=trainable, **kwargs)\n",
    "\n",
    "    def compute_size(self, shape):\n",
    "        size = np.array(shape)[[1, 2]] * self.scale\n",
    "        return tuple(size.astype(int))\n",
    "\n",
    "    def call(self, x):\n",
    "        size = self.compute_size(x.shape.as_list())\n",
    "        return tf.image.resize_images(x, size, method=self.method)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        size = self.compute_size(input_shape)\n",
    "        return (input_shape[0], *size, input_shape[3])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['scale'] = self.scale\n",
    "        config['method'] = self.method\n",
    "        return config\n",
    "\n",
    "def bicubic(x, scale=3):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=x.shape[-3:]))\n",
    "    model.add(ImageRescale(scale, method=tf.image.ResizeMethod.BICUBIC))\n",
    "    return model\n",
    "\n",
    "def srcnn(x, f=[9, 1, 5], n=[64, 32], scale=3):\n",
    "    assert len(f) == len(n) + 1\n",
    "    model = bicubic(x, scale=scale)\n",
    "    c = x.shape[-1]\n",
    "    for ni, fi in zip(n, f):\n",
    "        model.add(Conv2D(ni, fi, padding='same',\n",
    "                         kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(Conv2D(c, f[-1], padding='same',\n",
    "                     kernel_initializer='he_normal'))\n",
    "    return model\n",
    "\n",
    "def psnr(y_true, y_pred):\n",
    "    \"\"\"Peak signal-to-noise ratio averaged over samples and channels.\"\"\"\n",
    "    mse = K.mean(K.square(y_true - y_pred), axis=(-3, -2))\n",
    "    return K.mean(20 * K.log(255 / K.sqrt(mse)) / np.log(10))\n",
    "\n",
    "def print_statistic(gx):\n",
    "    print('Image shape is :' + str(gx.shape))\n",
    "    print('Image range from %f to %f' % (np.amin(gx), np.amax(gx)))\n",
    "    print('The length of the range is %f' % np.ptp(gx))\n",
    "    print('data type is ' + str(gx.dtype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(y_true, y_pred):\n",
    "    \"\"\"Peak signal-to-noise ratio averaged over samples and channels.\"\"\"\n",
    "    mse = K.mean(K.square(y_true - y_pred), axis=(-3, -2))\n",
    "    return K.mean(20 * K.log(255 / K.sqrt(mse)) / np.log(10))\n",
    "\n",
    "def hevc_gray_upscale(img_gray):\n",
    "    img_gray = np.int64(img_gray) -127\n",
    "    \n",
    "    taps14 = np.array([-1,4,-10,58,17,-5,1])\n",
    "    taps12 = np.array([-1,4,-11,40,40,-11,4,-1])\n",
    "    taps34 = np.flip(taps14)\n",
    "    scale = 4\n",
    "    datatype = np.int64\n",
    "    # pad zeros to the side\n",
    "    pad_zero_left = np.zeros((img_gray.shape[0], 3), dtype=datatype)\n",
    "    pad_zero_right = np.zeros((img_gray.shape[0], 4), dtype=datatype)\n",
    "    img_gray_pad = np.c_[pad_zero_left, img_gray, pad_zero_right]\n",
    "\n",
    "    pad_zero_up = np.zeros((3, img_gray_pad.shape[1]), dtype=datatype)\n",
    "    pad_zero_down = np.zeros((4, img_gray_pad.shape[1]), dtype=datatype)\n",
    "    img_gray_pad = np.r_[pad_zero_up, img_gray_pad, pad_zero_down]\n",
    "\n",
    "    img_upscale = np.zeros(np.array(img_gray_pad.shape) * scale, dtype=datatype)\n",
    "\n",
    "    # pixel interpolated using original image\n",
    "    for x in range(3, img_gray_pad.shape[0] - 4): #row\n",
    "        for y in range(3, img_gray_pad.shape[1] - 4): # column\n",
    "            X = x * scale\n",
    "            Y = y * scale\n",
    "\n",
    "            img_upscale[X, Y] = img_gray_pad[x,y] * 64\n",
    "            img_upscale[X, Y + 1] = np.sum(np.multiply(taps14, img_gray_pad[x, y-3:y+4]))\n",
    "            img_upscale[X, Y + 2] = np.sum(np.multiply(taps12, img_gray_pad[x, y-3:y+5]))\n",
    "            img_upscale[X, Y + 3] = np.sum(np.multiply(taps34, img_gray_pad[x, y-2:y+5]))\n",
    "            img_upscale[X + 1, Y] = np.sum(np.multiply(taps14, img_gray_pad[x-3:x+4, y]))\n",
    "            img_upscale[X + 2, Y] = np.sum(np.multiply(taps12, img_gray_pad[x-3:x+5, y]))\n",
    "            img_upscale[X + 3, Y] = np.sum(np.multiply(taps34, img_gray_pad[x-2:x+5, y]))\n",
    "\n",
    "    # pixel interpolated in the middle\n",
    "    for x in range(3, img_gray_pad.shape[0] - 4): #row\n",
    "        for y in range(3, img_gray_pad.shape[1] - 4): # column    \n",
    "            X = x * scale\n",
    "            Y = y * scale\n",
    "            img_upscale[X + 1, Y + 1] = np.right_shift(np.sum(np.multiply(taps14, img_upscale[X-3*scale : X+4*scale : scale, Y + 1])), 6)\n",
    "            img_upscale[X + 1, Y + 2] = np.right_shift(np.sum(np.multiply(taps14, img_upscale[X-3*scale : X+4*scale : scale, Y + 2])), 6)\n",
    "            img_upscale[X + 1, Y + 3] = np.right_shift(np.sum(np.multiply(taps14, img_upscale[X-3*scale : X+4*scale : scale, Y + 3])), 6)\n",
    "            img_upscale[X + 2, Y + 1] = np.right_shift(np.sum(np.multiply(taps12, img_upscale[X-3*scale : X+5*scale : scale, Y + 1])), 6)\n",
    "            img_upscale[X + 2, Y + 2] = np.right_shift(np.sum(np.multiply(taps12, img_upscale[X-3*scale : X+5*scale : scale, Y + 2])), 6)\n",
    "            img_upscale[X + 2, Y + 3] = np.right_shift(np.sum(np.multiply(taps12, img_upscale[X-3*scale : X+5*scale : scale, Y + 3])), 6)\n",
    "            img_upscale[X + 3, Y + 1] = np.right_shift(np.sum(np.multiply(taps34, img_upscale[X-2*scale : X+5*scale : scale, Y + 1])), 6)\n",
    "            img_upscale[X + 3, Y + 2] = np.right_shift(np.sum(np.multiply(taps34, img_upscale[X-2*scale : X+5*scale : scale, Y + 2])), 6)\n",
    "            img_upscale[X + 3, Y + 3] = np.right_shift(np.sum(np.multiply(taps34, img_upscale[X-2*scale : X+5*scale : scale, Y + 3])), 6)\n",
    "    \n",
    "    # normalization\n",
    "    img_upscale = (img_upscale - np.min(img_upscale))\n",
    "    img_upscale = img_upscale / np.max(img_upscale)\n",
    "    img_upscale = np.uint8(img_upscale*255)\n",
    "    # crop back to original size\n",
    "    img_upscale = img_upscale[3*scale:-4*scale, 3*scale:-4*scale]\n",
    "    \n",
    "    return img_upscale\n",
    "\n",
    "\n",
    "def test_one_image_hevc(image_dir, prefix, suffix='png', metrics=[psnr], scale=4):\n",
    "    image = load_img(image_dir)\n",
    "    image = image.convert('YCbCr')\n",
    "    hr_image = modcrop(image, scale)\n",
    "    lr_image = bicubic_rescale(hr_image, 1 / scale)\n",
    "    x = img_to_array(lr_image)[np.newaxis, ...]\n",
    "    bicubic_model = bicubic(x, scale=scale)\n",
    "    y = bicubic_model.predict_on_batch(x)\n",
    "    bicubic_array = np.clip(y[0], 0, 255)\n",
    "    \n",
    "    x_gray = pre_process(x)\n",
    "    start = time.perf_counter()\n",
    "    img_sr_hevc = hevc_gray_upscale(x_gray[0,:,:,0])\n",
    "    end = time.perf_counter()\n",
    "    img_output_hevc_chrom_bicubic = np.zeros((img_sr_hevc.shape[0],img_sr_hevc.shape[1],3), dtype=np.uint8)\n",
    "    img_output_hevc_chrom_bicubic[:,:,0] = img_sr_hevc\n",
    "    img_output_hevc_chrom_bicubic[:,:,1] = bicubic_array[..., 1]\n",
    "    img_output_hevc_chrom_bicubic[:,:,2] = bicubic_array[..., 2]\n",
    "    img_output_hevc_chrom_bicubic = Image.fromarray(img_output_hevc_chrom_bicubic, mode='YCbCr')\n",
    "#     img_output_hevc_chrom_bicubic.convert('RGB').save(str(save_dir / ('hevc_'+file_name)))\n",
    "\n",
    "    row_hevc = pd.Series()\n",
    "    row_hevc['name'] = Path(image_dir).stem\n",
    "    row_hevc['time'] = end - start\n",
    "    y_true = inverse_post_process(img_to_array(hr_image))\n",
    "    metrics=[psnr]\n",
    "    for metric in metrics:\n",
    "        row_hevc[metric.__name__] = K.eval(metric(y_true, img_sr_hevc[np.newaxis, ..., np.newaxis]))\n",
    "    # Save images\n",
    "    images_to_save = []\n",
    "    images_to_save += [(hr_image, 'original')]\n",
    "    images_to_save += [(img_output_hevc_chrom_bicubic, 'output')]\n",
    "    images_to_save += [(lr_image, 'input')]\n",
    "    for img, label in images_to_save:\n",
    "        img.convert(mode='RGB').save('.'.join([prefix, label, suffix]))\n",
    "\n",
    "    return row_hevc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(repo_dir) / 'experiments' / 'hevc-sc4'\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "test_dir = save_dir / 'test'\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "data_dir = Path(repo_dir) / 'data' / 'mytest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Set14\n"
     ]
    }
   ],
   "source": [
    "test_set='Set14'\n",
    "metrics=[psnr]\n",
    "print('Test on', test_set)\n",
    "image_dir = test_dir / test_set\n",
    "image_dir.mkdir(exist_ok=True)\n",
    "data_dir = Path(repo_dir) / 'data'\n",
    "# Evaluate metrics on each image\n",
    "rows = []\n",
    "for image_path in (data_dir / test_set).glob('*'):\n",
    "    rows += [test_one_image_hevc(str(image_path),str(image_dir / image_path.stem),metrics=metrics)]\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Compute average metrics\n",
    "row = pd.Series()\n",
    "row['name'] = 'average'\n",
    "for col in df:\n",
    "    if col != 'name':\n",
    "        row[col] = df[col].mean()\n",
    "df = df.append(row, ignore_index=True)\n",
    "\n",
    "df.to_csv(str(test_dir / f'{test_set}/metrics.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>psnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foreman</td>\n",
       "      <td>0.655279</td>\n",
       "      <td>20.399267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>man</td>\n",
       "      <td>1.709420</td>\n",
       "      <td>18.013014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pepper</td>\n",
       "      <td>1.711894</td>\n",
       "      <td>20.816298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comic</td>\n",
       "      <td>0.573778</td>\n",
       "      <td>17.448311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coastguard</td>\n",
       "      <td>0.693888</td>\n",
       "      <td>21.656029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baboon</td>\n",
       "      <td>1.554434</td>\n",
       "      <td>15.088350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>monarch</td>\n",
       "      <td>2.684909</td>\n",
       "      <td>22.513008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>flowers</td>\n",
       "      <td>1.163277</td>\n",
       "      <td>21.038273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>face</td>\n",
       "      <td>0.518917</td>\n",
       "      <td>23.048426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ppt3</td>\n",
       "      <td>2.279411</td>\n",
       "      <td>16.386860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zebra</td>\n",
       "      <td>1.478324</td>\n",
       "      <td>18.968500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bridge</td>\n",
       "      <td>1.753992</td>\n",
       "      <td>20.011860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>barbara</td>\n",
       "      <td>2.770983</td>\n",
       "      <td>18.977381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lenna</td>\n",
       "      <td>1.773349</td>\n",
       "      <td>23.019260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>average</td>\n",
       "      <td>1.522990</td>\n",
       "      <td>19.813203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name      time       psnr\n",
       "0      foreman  0.655279  20.399267\n",
       "1          man  1.709420  18.013014\n",
       "2       pepper  1.711894  20.816298\n",
       "3        comic  0.573778  17.448311\n",
       "4   coastguard  0.693888  21.656029\n",
       "5       baboon  1.554434  15.088350\n",
       "6      monarch  2.684909  22.513008\n",
       "7      flowers  1.163277  21.038273\n",
       "8         face  0.518917  23.048426\n",
       "9         ppt3  2.279411  16.386860\n",
       "10       zebra  1.478324  18.968500\n",
       "11      bridge  1.753992  20.011860\n",
       "12     barbara  2.770983  18.977381\n",
       "13       lenna  1.773349  23.019260\n",
       "14     average  1.522990  19.813203"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
